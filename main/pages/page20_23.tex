% Contenido de las Páginas 20-23 (Material Intent)
\section*{Pages 20-23 – VV-F – MATERIAL INTENT OF THE PROJECT}

\section{Excellence}

The project “Development of an Intelligent Drone System for Agricultural Monitoring with AI Analysis (AGRI-DRONE-AI)” aims to create an integrated platform that combines multispectral drone imaging, edge-AI processing and satellite-weather data fusion to improve precision agriculture in the Slovak Republic.

\subsection*{The originality lies in:}
\begin{enumerate}[label=(\alph*)]
    \item Real-time on-board AI inference for pest, disease and nutrient-stress detection directly in the drone’s edge-computing unit;
    \item Predictive analytics that merge drone imagery with Copernicus EU satellite data and local weather-station feeds;
    \item Actionable agronomic dashboards delivering field-level recommendations to farmers within minutes of a flight.
\end{enumerate}

Current agricultural drone solutions (e.g., DJI Agriculture, PrecisionHawk) mostly supply raw imagery that requires offline processing; our concept shortens the decision cycle and reduces dependency on external IT infrastructure.

\subsection*{State-of-the-art}
EU agriculture-drone market is forecast to reach \euro 7.46 billion by 2025. Research shows that timely pest-detection can reduce yield loss by 15-25 \% and cut pesticide use by up to 30 \%. The team builds on prior national pilot studies in multispectral monitoring of wheat and maize (2023-24) and an internal prototype for CNN-based leaf-disease recognition (accuracy $\approx 92\,\%$)
.
\subsection*{Project objectives:}
\begin{itemize}
    \item Design drone-sensor architecture and edge-AI pipeline for crop-health assessment.
    \item Develop \& train computer-vision models for pest/disease and irrigation-stress recognition.
    \item Integrate predictive models with weather/soil-sensor data for yield-improvement guidance.
    \item Field-validate the prototype on at least 200 ha of pilot farms in western and eastern Slovakia.
    \item Deliver a tested software prototype, AI integration methodology and best-practice adoption guidelines.
\end{itemize}

\subsection*{Feasibility}
Availability of commercial drones and GPUs plus our lab’s prior datasets make the objectives realistic within 36 months.

\subsection*{Principal Investigator’s key outputs (last 5 years – illustrative):}
\begin{itemize}
    \item Prototype CNN for wheat-rust detection (TRL 5 $\to$ yield loss $\downarrow 18\,\%$)
.
    \item Co-author of 2 EU-Horizon papers on precision-agriculture AI.
    \item Open-source soil-moisture fusion algorithm (adopted by 3 regional start-ups).
\end{itemize}

\subsection*{Competence of partners:}
\begin{itemize}
    \item Applicant organisation brings agronomy test-fields and UAV-pilot team.
    \item Co-operating university contributes expertise in deep-learning and remote-sensing.
    \item Industrial partner (AgroTech Solutions s.r.o.) will advise on market transfer.
\end{itemize}

\subsection*{Involvement of young researchers:}
4 PhD students (AI \& Robotics, age $\leq 30$) plus 2 MSc students in geoinformatics will join data-labelling, field-validation and dissemination tasks.

% --- SECCIÓN 2 ---
\section{Impact}

The system is expected to raise crop yield by 15-25 \% and reduce pesticide consumption by 20-30 \%, bringing tangible economic savings (lower chemical cost, higher production) and environmental benefits (less soil and water contamination, contribution to EU Green Deal).

\subsection*{For Slovak farmers}
Faster detection of pest/disease outbreaks can save up to \euro 150-200/ha in treatment costs.

\subsection*{For the agri-tech market}
Creates a transferable methodology for other EU regions and supports emerging climate-smart-farming services.

\subsection*{Societal benefits}
Improved food-security, higher-quality products, reduction of greenhouse-gas emissions from over-fertilisation, and new skilled jobs in drone operations and AI-data services.

\subsection*{Maximising results \& communication}
\begin{itemize}
    \item Public field-days with farmers’ associations each season;
    \item Open-access publication of core AI methodology after IP review;
    \item Workshops with Ministry of Agriculture and regional co-ops for adoption guidelines;
    \item Popular-science articles and short explainer videos for the public.
\end{itemize}

% --- SECCIÓN 3 ---
\section{Implementation}

\subsection*{Work plan \& milestones (36 months):}
\begin{description}
    \item[WP1 (M1-M6):] Market survey \& system design $\to$ Spec-sheet for drones + AI pipeline.
    \item[WP2 (M4-M14):] Data collection (multispectral flights, soil-sensor network) $\to$ Curated labelled dataset $\geq 50$k images.
    \item[WP3 (M8-M18):] Model development \& training $\to$ Baseline AI model (mAP $\geq 0.80$) for pest/disease detection.
    \item[WP4 (M15-M26):] Hardware integration \& edge-AI deployment $\to$ Prototype UAV-AI platform TRL 6.
    \item[WP5 (M20-M34):] Pilot-field trials on 200 ha farms $\to$ Validated performance ($\geq 20\,\%$ yield-gain vs. control).
    \item[WP6 (M30-M36):] Final optimization, user-manuals \& technology-transfer package $\to$ Software prototype + guidelines.
\end{description}

\subsection*{Project management}
Steering committee (PI + one rep per partner); monthly progress reviews; risk-log monitored in cloud-based PM tool.

\subsection*{Risks \& mitigation}
\begin{itemize}
    \item Bad weather limiting drone flights $\to$ buffer period \& alternative indoor test-beds.
    \item Insufficient labelled data $\to$ semi-synthetic data-augmentation \& transfer-learning.
    \item Hardware failure $\to$ redundant drone unit + maintenance contract.
\end{itemize}

\subsection*{Budget adequacy}
45 \% equipment (drones, GPU server, sensors), 40 \% personnel (AI researchers, agronomy experts), 15 \% travel, dissemination \& popularisation – proportionate to stated goals and TRL advancement.

\subsection*{Existing infrastructure}
Applicant owns 2 test fields (30 ha each), UAV-flight-permit and basic drone fleet; university partner operates AI computing cluster (200 TFLOPS) and spectral calibration lab.
